
### Recording Rule


---

یک اسکِم نام‌گذاری ثابت برای Recording Rule باعث می‌شود که معنیِ یک قاعده به‌راحتی در نگاه اول قابل فهم باشد. همچنین از بروز اشتباهات، مثلاً محاسبات نادرست یا بی‌معنی جلوگیری می‌کند.
در این صفحه، نام‌گذاری صحیح و گردآوری (Aggregation) برای Recording Rule توضیح داده شده است.


---

#### نام‌گذاری

*  همینطور Recording Rule باید به شکل کلی زیر باشند:
  `level:metric:operations` 
* ‏`level` نشان‌دهندهٔ سطحِ گردآوری و برچسب‌های Recording rules است. 
* ‏`metric` اسم متریک است و باید بدون تغییر باقی بماند، به‌جز این‌که اگر یک کانتر (`_total`) را با `rate()` یا `irate()` استفاده می‌کنید، آن قسمت `_total` را حذف می‌کنید. 
* ‏`operations` فهرستی از عملیاتی است که بر روی متریک انجام شده‌اند، که جدیدترین عملیات اول نوشته می‌شوند.
نگه‌داشتن اسم متریک بدون تغییر باعث می‌شود که تشخیص آن آسان‌تر شود و یافتنش در کد یا محاسبات راحت‌تر باشد. 
برای نگه‌داشتن عملیات واضح، اگر عملیاتی `sum()` است و متریک خودش `_sum` ندارد، آن را حذف می‌کنیم. مثلاً اگر `min_min` باشد، همان `min` حساب می‌شود. 
اگر عملیاتی واضح نیست، از `sum` استفاده کنید. زمانی که بخواهید نسبت بگیرید (division) بین متریک‌ها، از `_per_` برای جداسازی اسم متریک‌ها استفاده کنید و عملیات را `ratio` نام‌گذاری کنید. 


---

#### گردآوری (Aggregation)

* وقتی نسبت‌ها را گردآوری می‌کنید، ابتدا صورت و مخرج را جداگانه جمع بزنید، سپس تقسیم کنید.
* از گرفتن میانگین نسبت یا میانگین میانگین خودداری کنید، چون از لحاظ آماری معتبر نیست. 
* در زمانی که با Summary سروکار دارید (مثلاً `_count` و `_sum`) و می‌خواهید میانگین مشاهدات را حساب کنید، اسم متریک را بدون پسوند `_count` یا `_sum` نگه‌دارید و `rate` را با `mean` جایگزین کنید؛ چون این کار نمایانگر میانگین اندازهٔ مشاهده‌ها در دورهٔ زمانی است. 
* همیشه از عبارت `without` با برچسب‌هایی که در حال گردآوری‌شدن هستند استفاده کنید. این کار باعث می‌شود که سایر برچسب‌ها مانند `job` حفظ شوند، و از بروز تداخل‌ها جلوگیری شود و متریک‌ها و هشدارها مفیدتر شوند. 


#### مثال‌ها

در ادامه چند مثال آمده است: 

* بررسی  aggregating نرخ درخواست‌ها در ثانیه با برچسب `path`:

  ```yaml
  - record: instance_path:requests:rate5m
    expr: rate(requests_total{job="myjob"}[5m])

  - record: path:requests:rate5m
    expr: sum without (instance)(instance_path:requests:rate5m{job="myjob"})
  ```
* محاسبهٔ نسبت خطاهای درخواست:

  ```yaml
  - record: instance_path:request_failures:rate5m
    expr: rate(request_failures_total{job="myjob"}[5m])

  - record: instance_path:request_failures_per_requests:ratio_rate5m
    expr: |
      instance_path:request_failures:rate5m{job="myjob"}
    /
      instance_path:requests:rate5m{job="myjob"}

  - record: path:request_failures_per_requests:ratio_rate5m
    expr: |
      sum without (instance)(instance_path:request_failures:rate5m{job="myjob"})
    /
      sum without (instance)(instance_path:requests:rate5m{job="myjob"})
  ```

  و سپس aggregating تا سطح job:

  ```yaml
  - record: job:request_failures_per_requests:ratio_rate5m
    expr: |
      sum without (instance, path)(instance_path:request_failures:rate5m{job="myjob"})
    /
      sum without (instance, path)(instance_path:requests:rate5m{job="myjob"})
  ```
* محاسبهٔ میانگین تاخیر از یک Summary:

  ```yaml
  - record: instance_path:request_latency_seconds_count:rate5m
    expr: rate(request_latency_seconds_count{job="myjob"}[5m])

  - record: instance_path:request_latency_seconds_sum:rate5m
    expr: rate(request_latency_seconds_sum{job="myjob"}[5m])

  - record: instance_path:request_latency_seconds:mean5m
    expr: |
      instance_path:request_latency_seconds_sum:rate5m{job="myjob"}
    /
      instance_path:request_latency_seconds_count:rate5m{job="myjob"}

  - record: path:request_latency_seconds:mean5m
    expr: |
      sum without (instance)(instance_path:request_latency_seconds_sum:rate5m{job="myjob"})
    /
      sum without (instance)(instance_path:request_latency_seconds_count:rate5m{job="myjob"})
  ```
* محاسبهٔ نرخ میانگین پرس‌وجوها در طول نمونه‌ها و مسیرها با استفاده از `avg()`:

  ```yaml
  - record: job:request_latency_seconds_count:avg_rate5m
    expr: avg without (instance, path)(instance_path:request_latency_seconds_count:rate5m{job="myjob"})
  ```

نکته: وقتی aggregating می‌کنید، برچسب‌هایی که در `without` ایندکس شده‌اند، از سطح اسم متریک خروجی حذف می‌شوند؛ اگر level خروجی با level ورودی مطابقت ندارد، احتمالاً در rule اشتباهی رخ داده است.



---

### تعریف Recording Rule

#### پیکربندی قواعد

این Prometheus از دو نوع قاعده پشتیبانی می‌کند که می‌توان آن‌ها را پیکربندی کرده و در فواصل منظم ارزیابی نمود: **Recording Rule** (recording rules) و **قواعد هشداردهی** (alerting rules). 
برای اینکه قواعد را در Prometheus وارد کنید، یک فایل حاوی دستورهای مربوطه بسازید و آن را از طریق فیلد `rule_files` در پیکربندی Prometheus بارگذاری کنید. فایل‌های قاعده باید به فرمت YAML باشند. 
فایل‌های قاعده در زمان اجرا نیز قابل بازخوانی هستند؛ کافی است به فرایند Prometheus سیگنال `SIGHUP` ارسال شود. تغییرات فقط زمانی اعمال می‌شوند که همه فایل‌های قاعده، درست فرمت شده باشند. 

#### بررسی سینتکس فایل قواعد

برای اینکه سریع بررسی کنید آیا فایل قواعد از نظر نحوی درست است بدون اینکه سرور Prometheus را راه‌اندازی کنید، می‌توانید از ابزار خط فرمان `promtool` استفاده نمایید: 

```
promtool check rules /path/to/example.rules.yml
```

اگر فایل از نظر سینتکس معتبر باشد، ابزار بازنمایی متنی قواعد را چاپ می‌کند و با کد خروجی 0 خاتمه می‌یابد. اگر خطا وجود داشته باشد، پیام خطا به stderr چاپ می‌شود و با کد خروجی 1 پایان می‌یابد. 

#### Recording Rule

یک Recording Rule به شما اجازه می‌دهند که عبارات پرس‌و‌جو (PromQL) که به‌طور مکرر مورد نیازند یا محاسباتشان سنگین است را از پیش محاسبه کنید و نتیجه را به‌صورت یک مجموعهٔ جدید از سری‌های زمانی ذخیره نمایید. سپس پرس‌وجو بر روی نتیجهٔ از پیش محاسبه‌شده معمولاً بسیار سریع‌تر خواهد بود نسبت به اجرای عبارت اصلی هر بار. این موضوع به‌ویژه برای داشبوردهایی مفید است که با هر تازه‌سازی همان عبارت را مجدداً اجرا می‌کنند. 
در Recording Rule و قواعد هشداردهی هر دو درون «گروه قاعده» (rule group) قرار می‌گیرند. قواعد درون یک گروه به‌صورت متوالی اجرا می‌شوند و زمان ارزیابی یکسانی دارند. 
نام Recording Rule باید **یک نام معتبر برای متریک‌ها** باشد. 

#### ساختار فایل قاعده

ساختار کلی فایل YAML قاعده به این شکل است: 

```yaml
groups:
  - name: <rule_group>
    rules:
      - record: <string>
        expr: <string>
        labels:
          <labelname>: <labelvalue>
```

و همچنین پارامترهای اختیاری برای گروه‌ها: 

* ‏`interval: <duration>` | پیش‌فرض = `global.evaluation_interval`
* ‏`limit: <int>` | پیش‌فرض = 0 — محدودیت تعداد سر‌ی‌های تولیدشده توسط Recording Rule یا هشداردهی
* ‏`query_offset: <duration>` | پیش‌فرض = `global.rule_query_offset` — افست زمانی برای پرس‌وجو
* ‏`labels:` — برچسب‌هایی که قبل از ذخیرهٔ نتیجه اضافه یا بازنویسی می‌شوند.

#### مثال

یک مثال ساده از فایل قواعد: 

```yaml
groups:
  - name: example
    rules:
      - record: code:prometheus_http_requests_total:sum
        expr: sum by (code) (prometheus_http_requests_total)
```

#### محدود کردن هشدارها و سری‌ها

محدودیتی برای تعداد هشدارهایی که قواعد هشداردهی تولید می‌کنند و سری‌هایی که Recording Rule تولید می‌کنند قابل تنظیم است. زمانی که محدودیت تجاوز شود، تمام سری تولیدشده توسط آن قاعده حذف خواهند شد، و در مورد قواعد هشداردهی، تمام هشدارها (فعال، در انتظار، یا غیرفعال) نیز پاک می‌شوند. این رویداد به‌عنوان یک خطا در ارزیابی ثبت می‌شود.

#### بررسی Rule Query Offset

این گزینه زمانی مفید است که بخواهید مطمئن شوید **Underlying Metrics** قبل از اجرای Rule دریافت و ذخیره شده‌اند. تأخیر در در دسترس شدن متریک‌ها بیشتر زمانی رخ می‌دهد که Prometheus به‌عنوان یک هدف “remote write” اجرا شود یا زمانی که اسکرِیپ یا ارزیابی به‌صورت غیرمعمولی دیر انجام شود.

#### ارزیابی ناموفق قواعد به‌خاطر ارزیابی کند

اگر Recording Rule، ارزیابی خود را قبل از زمان بعدی ارزیابی (بر اساس `evaluation_interval`) به پایان نرساند، آن ارزیابی بعدی رد می‌شود. ارزیابی‌های بعدی گروه قاعده نیز تا زمانی که ارزیابی فعلی یا به پایان برسد یا تایم‌اوت شود، رد خواهند شد. در این حالت شکاف (gap) در متریک تولیدشده توسط  Recording Rule دیده خواهد شد. متریک `rule_group_iterations_missed_total` برای هر اجرای از دست‌رفته افزایش می‌یابد. 

[1]: https://prometheus.io/docs/prometheus/latest/configuration/recording_rules/ "Defining recording rules | Prometheus"







------


### چرا **گرفتن "میانگین میانگین‌ها" (Average of Averages) از نظر آماری معتبر نیست**?

زیرا می‌تواند به یک شاخص گمراه‌کننده و اشتباه منجر شود.

دلیل اصلی این است که این روش **حجم یا وزن (Weight)** گروه‌های مختلف را نادیده می‌گیرد.

---

### تشریح مشکل با یک مثال ساده

فرض کنید یک مدرسه کوچک با دو کلاس داریم و می‌خواهیم میانگین نمره کل دانش‌آموزان مدرسه را محاسبه کنیم.

| کلاس | تعداد دانش‌آموز (Weight) | میانگین نمره کلاس |
| :--- | :--- | :--- |
| **A** | ۱۰ دانش‌آموز | ۱۹ (از ۲۰) |
| **B** | ۴۰ دانش‌آموز | ۱۴ (از ۲۰) |

**حالا دو روش برای محاسبه میانگین کل داریم:**

#### ۱. روش صحیح: میانگین موزون (Weighted Average)

در این روش، به هر میانگین، با توجه به تعداد دانش‌آموزانش "وزن" داده می‌شود.

میانگین کل = ( (تعداد کلاس A × میانگین کلاس A) + (تعداد کلاس B × میانگین کلاس B) ) ÷ مجموع کل دانش‌آموزان
$$
( (10 × 19) + (40 × 14) ) / (10 + 40) = (190 + 560) / 50 = 750 / 50 = 15
$$


**نتیجه صحیح: ۱۵**

#### ۲. روش نادرست: میانگین میانگین‌ها (Average of Averages)

در این روش، ما به سادگی میانگین دو عدد ۱۹ و ۱۴ را حساب می‌کنیم.

$$
(19 + 14) / 2 = 33 / 2 = 16.5
$$
**نتیجه نادرست: ۱۶.۵**

---

### تحلیل نتایج

همانطور که می‌بینید، دو نتیجه کاملاً متفاوت هستند (۱۵ در مقابل ۱۶.۵). دلیل این اختلاف این است:

*   کلاس **A** با وجود میانگین عالی (۱۹)، تنها ۲۰٪ از جمعیت مدرسه را تشکیل می‌دهد.
*   کلاس **B** با میانگین پایین‌تر (۱۴)، ۸۰٪ از جمعیت مدرسه را تشکیل می‌دهد.

وقتی ما میانگین میانگین‌ها را می‌گیریم، به هر دو کلاس به یک اندازه (۵۰-۵۰) اهمیت داده‌ایم، در حالی که تأثیر کلاس B بر روی میانگین کل مدرسه باید ۴ برابر کلاس A باشد. روش میانگین میانگین، این تفاوت عظیم در "وزن" گروه‌ها را کاملاً نادیده می‌گیرد.

---

### چه زمانی میانگین میانگین‌ها معتبر است؟

**تنها در یک شرایط خاص:** زمانی که تمام گروه‌ها **اندازه دقیقاً یکسانی** داشته باشند.

مثال: اگر هر دو کلاس ما ۲۵ دانش‌آموز داشتند:
*   روش صحیح:
$$  
 ( (25×19) + (25×14) ) / 50 = (475 + 350) / 50 = 16.5
 $$
 
*   روش میانگین میانگین: `(19 + 14) / 2 = 16.5`

در این حالت خاص، هر دو روش یک جواب می‌دهند.

---

### جمع‌بندی و مثال‌های کاربردی

| سناریو                                    | مشکل میانگین میانگین‌ها                                                                                              |
| :---------------------------------------- | :------------------------------------------------------------------------------------------------------------------- |
| **میانگین نمره دانشگاه‌های یک کشور**      | دانشگاهی با ۱۰۰۰ دانشجو و معدل ۱۷، تأثیر بسیار بیشتری از دانشگاهی با ۱۰۰ دانشجو و معدل ۱۹ دارد.                      |
| **میانگین حقوق در یک کشور**               | اگر میانگین حقوق یک شرکت کوچک (۱۰ کارمند) با یک شرکت بزرگ (۱۰۰۰۰ کارمند) را میانگین بگیریم، نتیجه بی‌معنا خواهد بود. |
| **میانگین نرخ بازدید از صفحات یک وبسایت** | صفحۀ اصلی با میلیون‌ها بازدید و نرخ پرش (Bounce Rate) پایین، بسیار مهم‌تر از یک صفحۀ فرعی با هزاران بازدید است.      |
| **میانگین عملکرد فروش مناطق مختلف**       | منطقه‌ای با یک فروشنده عالی و فروش بالا، نمی‌تواند میانگین ضعیف یک منطقه با ۵۰ فروشنده را جبران کند.                 |

### قاعده کلی

هرگاه زیرگروه‌هایی که از آنها میانگین گرفته‌اید **اندازه‌های متفاوتی** دارند، برای به دست آوردن میانگین کل، **حتماً باید از میانگین موزون (Weighted Average)** استفاده کنید.

AVG-> **میانگین موزون = Σ (وزن هر گروه × میانگین آن گروه) / Σ (وزن تمام گروه‌ها)**

در غیر این صورت، به نتیجه‌ای می‌رسید که نه تنها نادرست است، بلکه می‌تواند در تصمیم‌گیری‌های مهم منجر به خطاهای فاحش شود.







-----------


عالی سوال کردید. ارسال سیگنال `SIGHUP` به فرآیند Prometheus یک روش استاندارد برای **Reload کردن پیکربندی (Configuration Reload)** بدون نیاز به راه‌اندازی مجدد سرویس است.

این کار در موارد زیر مفید است:
*   شما فایل پیکربندی `prometheus.yml` را تغییر داده‌اید.
*   شما فایل‌های `rules.yml` (قوانین alerting/recording) را تغییر داده‌اید.
*   می‌خواهید Prometheus پیکربندی جدید را بارگذاری کند بدون از دست دادن داده‌های جمع‌آوری شده.

---

### نحوه انجام کار

#### ۱. پیدا کردن PID (Process ID) فرآیند Prometheus

ابتدا باید Process ID سرویس Prometheus را پیدا کنید.

**روش اول: استفاده از `ps`**
```bash
ps aux | grep prometheus
```
خروجی چیزی شبیه به این خواهد بود:
```
prometheus 1234  0.2  0.1 1023456 7890 ?  Ssl  10:00  0:30 /usr/bin/prometheus --config.file=/etc/prometheus/prometheus.yml ...
```
در این مثال، `PID` برابر است با `1234`.

**روش دوم: استفاده از `systemd` (اگر به عنوان سرویس اجرا شده)**
```bash
systemctl status prometheus
```
در خروجی، معمولاً PID قید شده است. اگر نبود، می‌توانید از این استفاده کنید:
```bash
sudo systemctl show prometheus --property=MainPID
```

**روش سوم: استفاده از `pgrep`**
```bash
pgrep prometheus
```

#### ۲. ارسال سیگنال `SIGHUP`

پس از پیدا کردن PID، سیگنال را با دستور `kill` ارسال کنید.

```bash
sudo kill -HUP 1234
```
یا
```bash
sudo kill -SIGHUP 1234
```

> **نکته مهم:** اگر Prometheus تحت کاربر خاصی (مثلاً `prometheus`) اجرا شده، مطمئن شوید که دستور را با دسترسی مناسب (مثلاً `sudo`) اجرا می‌کنید.

#### ۳. تأیید بارگذاری مجدد پیکربندی

برای اطمینان از اینکه پیکربندی با موفقیت reload شده است، **لاگ‌های Prometheus** را بررسی کنید.

**روش اول: مشاهده لاگ‌های `systemd`**
```bash
sudo journalctl -u prometheus -f
```

**روش دوم: مشاهده فایل لاگ (اگر از `systemd` استفاده نمی‌کند)**
```bash
tail -f /var/log/prometheus/prometheus.log
```

**پیام موفقیت‌آمیز در لاگ:**
شما باید پیامی مشابه زیر را ببینید که نشان می‌دهد پیکربندی با موفقیت بارگذاری مجدد شده است.
```
level=info ts=2023-10-25T12:34:56.789Z caller=main.go:755 msg="Loading configuration file" filename=/etc/prometheus/prometheus.yml
level=info ts=2023-10-25T12:34:56.790Z caller=main.go:786 msg="Completed loading of configuration file" filename=/etc/prometheus/prometheus.yml
level=info ts=2023-10-25T12:34:56.790Z caller=main.go:604 msg="Server is ready to receive web requests."
```

---

### اگر از `systemd` استفاده می‌کنید (روش ترجیحی)

اگر Prometheus را به عنوان یک سرویس `systemd` مدیریت می‌کنید، می‌توانید از دستور `reload` استفاده کنید که در پشت صحنه همان سیگنال `SIGHUP` را ارسال می‌کند.

```bash
sudo systemctl reload prometheus
```

این روش تمیزتر و مدیریت‌شده‌تر است و نیازی به دانستن PID ندارد.

---

### محدودیت‌های `SIGHUP`

مهم است که بدانید `SIGHUP` **چه چیزهایی را Reload می‌کند و چه چیزهایی را نمی‌کند**:

| مواردی که **Reload** می‌شوند               | مواردی که **Reload نمی‌شوند**                              |
| :----------------------------------------- | :--------------------------------------------------------- |
| فایل پیکربندی اصلی (`prometheus.yml`)      | `flags` یا پارامترهای خط فرمان (مثل `--storage.tsdb.path`) |
| فایل‌های Rule (قوانین Alerting/Recording)  | تنظیمات مربوط به ذخیره‌سازی (Storage)                      |
| فایل `file_sd_configs` (Service Discovery) | طرح‌بندی (Schema) پایگاه داده TSDB                         |
| تنظیمات `scrape_configs`                   |                                                            |

برای اعمال تغییراتی که با `SIGHUP` قابل reload نیستند، شما **نیاز به راه‌اندازی مجدد کامل سرویس** دارید:
```bash
sudo systemctl restart prometheus
```

### جمع‌بندی

*   **دستور:** `kill -HUP PID` یا `systemctl reload prometheus`
*   **هدف:** بارگذاری مجدد پیکربندی و قوانین بدون توقف سرویس.
*   **مزیت:** از دست نرفتن داده‌های جمع‌آوری شده در حین عملیات.
*   **نکته:** همیشه لاگ‌ها را برای اطمینان از موفقیت‌آمیز بودن عملیات بررسی کنید.

این قابلیت، Prometheus را برای مدیریت در محیط‌های production بسیار انعطاف‌پذیر می‌سازد.




---------------


٫٫٫٫ 



---

### هدف اصلی: جلوگیری از طوفان داده (Data Storm)

این مکانیزم برای محافظت از سرور Prometheus در مواقعی طراحی شده که یک **Rule** (چه از نوع Alerting و چه Recording) به دلایلی شروع به تولید حجم غیرعادی و بی‌سابقه‌ای از داده کند.

**دلایل رایج چنین اتفاقی:**
*   یک باگ در خود Rule (مثلاً یک regex نادرست).
*   یک تغییر ناگهانی در labelsهای متریک‌های پایه.
*   یک مشکل در برنامه که باعث تولید متریک‌های غیرعادی می‌شود.

بدون این محدودیت، چنین Rule معیوبی می‌تواند به راحتی حافظه Prometheus را پر کرده و آن را از کار بیندازد.

---

### نحوه کار و تنظیمات

این محدودیت در فایل پیکربندی قوانین (معمولاً `*.rules.yml`) و در سطح **Group** اعمال می‌شود. هر Group می‌تواند مجموعه‌ای از Ruleهای مرتبط باشد.

```yaml
# مثال تنظیم limit در یک group
groups:
  - name: example
    # تنظیم محدودیت در اینجا
    limit: 100  # این گروه مجاز به تولید حداکثر 100 سری زمانی یا alert است.
    rules:
      - record: job:http_inprogress_requests:sum
        expr: sum by (job) (http_inprogress_requests)
      - alert: HighRequestLatency
        expr: job:request_latency_seconds:mean5m{job="api"} > 0.5
        for: 10m
        annotations:
          summary: "High request latency on {{ $labels.job }}"
```

---

### وقتی محدودیت (Limit) رد می‌شود، چه اتفاقی می‌افتد؟



#### ۱. **داده‌ها دور ریخته می‌شوند (Discarded)**
*   تمام سری‌های زمانی (Series) که آن Rule تولید کرده است، **دور ریخته می‌شوند**. یعنی هیچ کدام از آن داده‌ها در پایگاه داده (TSDB) ذخیره یا به روز نمی‌شوند.

#### ۲. **Alertها پاک می‌شوند (Cleared)**
*   اگر Rule از نوع **Alerting** باشد، تمام Alertهای مربوط به آن Rule—چه در حالت `active`، `pending` و چه `inactive`—**پاک می‌شوند**. این Alertها از Alertmanager حذف شده و دیگر هیچ هشداری برای آن Rule ارسال نمی‌شود.

#### ۳. **ثبت خطا (Error Recorded)**
*   این رویداد به عنوان یک **خطا (Error)** در هنگام ارزیابی (Evaluation) Rule ثبت می‌شود. شما می‌توانید این خطاها را در لاگ‌های Prometheus ببینید.

#### ۴. **عدم نوشتن "Stale Markers"**
*   از آنجایی که کل خروجی Rule به عنوان یک خطا در نظر گرفته شده و دور ریخته می‌شود، Prometheus "نشانگرهای کهنه" (Stale Markers) نیز برای آن داده‌ها نوشته نمی‌شود. (Stale Markers معمولاً برای نشان دادن عدم به روزرسانی یک سری زمانی استفاده می‌شوند.)

---

### یک سناریو فرضی

فرض کنید یک Recording Rule به شکل زیر دارید که محدودیت گروه آن ۱۰۰۰ است:

```yaml
groups:
  - name: my_service
    limit: 1000
    rules:
      - record: high_cardinality_metric:by_pod
        expr: some_metric * by (pod) (another_metric)
```

حالا تصور کنید به دلیل یک تغییر در زیرساخت، تعداد `pod`های شما از ۲۰ تا به ۱۵۰۰ تا افزایش یابد.

*   قاعده شما سعی می‌کند ۱۵۰۰ سری زمانی جدید (یک سری برای هر pod) تولید کند.
*   از آنجایی که این عدد از `limit=1000` بیشتر است، Prometheus:
    1.  از ذخیره کردن **هر ۱۵۰۰ سری** خودداری می‌کند.
    2.  یک خطا در لاگ می‌نویسد: `"msg="Rule returned more than 1000 samples, skipping update ..."`
    3.  داده‌های قبلی این Rule در TSDB به حالت "قدیمی" درمی‌آیند (چون به روزرسانی نمی‌شوند) اما Stale Marker مخصوصی برای این خطا نوشته نمی‌شود.

---

### چرا این رفتار منطقی است؟

این یک **مکانیزم "قطع کننده مدار (Circuit Breaker)"** است. وقتی یک Rule از کنترل خارج می‌شود، بهتر است که به طور کامل خاموش شود تا اینکه با تولید داده‌های غلط و بی‌رویه، کل سیستم مانیتورینگ را به خطر بیندازد.

**مزایا:**
*   از بارگذاری بیش از حد روی Prometheus جلوگیری می‌کند.
*   از اشغال حافظه و دیسک بی‌رویه جلوگیری می‌کند.
*   مهندسین را مجبور می‌کند تا قوانین خود را با دقت بیشتری طراحی کنند و کاردینالیتی را کنترل نمایند.

### جمع‌بندی

این ویژگی یک ابزار حیاتی برای مدیریت ریسک در Prometheus است. هنگام تعریف Ruleها، به ویژه آنهایی که ممکن است برچسب‌های با کاردینالیتی بالا داشته باشند، باید یک `limit` معقول و ایمن برای گروه آن‌ها در نظر گرفت تا از عواقب یک باگ یا تغییر ناگهانی در محیط در امان بود.













-----------


---

### مشکل اصلی: "رقابت برای داده" (Race Condition)

فرض کنید:
*   یک **Recording Rule** یا **Alerting Rule** دارید که هر **۱۵ ثانیه** اجرا می‌شود (evaluation interval).
*   این Rule بر اساس یک متریک پایه (underlying metric) است که یک **Target** هر **۱۵ ثانیه** scrape می‌شود.

یک سناریو رقابتی ممکن است به این شکل رخ دهد:
1.  در ثانیه `۰`: Rule ارزیابی می‌شود.
2.  در ثانیه `۱`: Target اسکراپ می‌شود و داده جدید جمع‌آوری می‌شود.
3.  **نتیجه:** در ارزیابی ثانیه `۰`، Rule از داده‌ای که ۱۴ ثانیه قبل جمع‌آوری شده استفاده می‌کند و داده جدیدی که در ثانیه `۱` آمده را از دست می‌دهد.

### راه‌حل: Query Offset

با استفاده از `query_offset`، به Rule می‌گویید: "هنگام ارزیابی، به جای نگاه کردن به داده‌های همین الان، به داده‌های X مدت قبل نگاه کن".

```yaml
groups:
  - name: example
    interval: 15s
    # به همه ruleهای این گروه می‌گوید 5 ثانیه به عقب نگاه کنند
    query_offset: 5s
    rules:
      - record: job:requests:rate5m
        expr: rate(http_requests_total[5m])
```

---

### چرا این ویژگی مفید است؟ (شرایط استفاده)

#### ۱. **هنگام استفاده از Remote Write (مورد اصلی)**

وقتی Prometheus به عنوان **Remote Write Target** عمل می‌کند (مثلاً در Prometheus Federation یا M3DB):
*   داده از یک Prometheus "ارسال‌کننده" به یک Prometheus "دریافت‌کننده" منتقل می‌شود.
*   این انتقال شبکه ممکن است **چند ثانیه تأخیر** داشته باشد.
*   اگر Ruleها در Prometheus دریافت‌کننده بلافاصله پس از دریافت داده ارزیابی شوند، ممکن است داده هنوز در TSDB ذخیره نشده باشد.
*   **راه‌حل:** استفاده از `query_offset: 3s` تا مطمئن شوید داده قبلاً ذخیره شده است.

#### ۲. **هنگام وجود آنومالی در اسکراپ (Scrape Anomalies)**

گاهی اوقات اسکراپ یک Target ممکن است:
*   بیشتر از حد معمول طول بکشد
*   به دلیل مشکلات شبکه با تأخیر مواجه شود
*   موقتاً fail شود و سپس recover گردد

این `query_offset` به داده زمان می‌دهد تا به حالت پایدار برسد.

#### ۳. **هنگام استفاده از evaluation interval کوتاه**

اگر interval ارزیابی Ruleها بسیار کوتاه باشد (مثلاً ۵ ثانیه)، احتمال همزمانی با اسکراپ افزایش می‌یابد. offset این تضاد زمانی را حل می‌کند.

---

### نحوه عملکرد فنی

```yaml
groups:
  - name: delayed_rules
    query_offset: 10s
    rules:
      - record: always_one
        expr: some_metric
```

**چه اتفاقی می‌افتد:**
*   اگر الان ساعت `14:35:00` باشد...
*   و Rule در حال ارزیابی باشد...
*   که Prometheus کوئری را به صورت `some_metric offset 10s` اجرا می‌کند...
*   یعنی داده‌های مربوط به زمان `14:34:50` را مورد پردازش قرار می‌دهد.

### مثال کاربردی: هماهنگ‌سازی اسکراپ و ارزیابی

```yaml
# تنظیمات اسکراپ
scrape_configs:
  - job_name: 'my_app'
    scrape_interval: 30s

# تنظیمات Rule
groups:
  - name: my_app_rules
    interval: 30s
    query_offset: 10s  # منتظر می‌ماند داده اسکراپ جدید ذخیره شود
    rules:
      - alert: AppDown
        expr: up{job="my_app"} == 0
        for: 2m
```

در این مثال:
*   اسکراپ هر ۳۰ ثانیه اتفاق می‌افتد
*    این Ruleها نیز هر ۳۰ ثانیه ارزیابی می‌شوند
*   اما Ruleها با تأخیر ۱۰ ثانیه‌ای ارزیابی می‌شوند
*   این تضمین می‌کند که داده اسکراپ جدید قبل از ارزیابی Ruleها در TSDB ذخیره شده است

---

### نکات مهم در implementation

1.  **مقدار بهینه:** `query_offset` باید کمی کمتر از `scrape_interval` باشد (مثلاً اگر scrape_interval=30s باشد، offset=25s مناسب است).

2.  **تأثیر روی داده:** این ویژگی داده‌ها را "عقب می‌اندازد"، بنابراین Ruleها همیشه بر اساس داده‌های کمی قدیمی‌تر کار می‌کنند. این برای اکثر سناریوهای مانیتورینگ قابل قبول است.

3.  **جایگزین نیست برای:** این ویژگی جایگزین `for` clause در Alerting Ruleها نمی‌شود. `for` برای مقاومت در برابر نوسانات موقت است، در حالی که `query_offset` برای حل مشکل همزمانی است.

4.  **لاگ‌ها:** اگر offset خیلی بزرگ باشد، ممکن است با خطای `"expression resulted in no samples"` مواجه شوید چون داده‌ها "خیلی قدیمی" هستند.

### جمع‌بندی

پس `query_offset` یک مکانیزم ساده اما قدرتمند برای:
*   **حل مشکل race condition** بین اسکراپ و ارزیابی
*   **اطمینان از در دسترس بودن داده** قبل از اجرای Ruleها  
*   **پایداری بیشتر** در محیط‌های توزیع‌شده و remote write

استفاده صحیح از آن می‌تواند از بسیاری از مشکلات متداول مانند alertهای از دست رفته، recording ruleهای ناقص و نوسانات در داده‌ها جلوگیری کند.