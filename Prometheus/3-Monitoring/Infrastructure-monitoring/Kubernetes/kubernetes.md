![image](src/prometheusKuber.png)




اجرای Prometheus در Kubernetes یک راه حل رایج و قدرتمند برای جمع‌آوری و نظارت بر متریک‌های مربوط به Podها و سایر اجزای کلاستر است. در اینجا مراحل و مفاهیم کلیدی برای انجام این کار آورده شده است:

**1. روش‌های جمع‌آوری متریک از Podها:**

قبل از استقرار Prometheus، باید بدانید که چگونه می‌توانید متریک‌ها را از Podهای خود جمع‌آوری کنید:

- ‏**Prometheus Exporterها:** رایج‌ترین روش این است که یک Exporter را در کنار برنامه کاربردی خود در یک Pod اجرا کنید. Exporter برنامه‌ای است که متریک‌های برنامه را در قالب قابل فهم برای Prometheus (/metrics endpoint) در معرض قرار می‌دهد. Exporterهای مختلفی برای زبان‌ها، فریم‌ورک‌ها و برنامه‌های کاربردی مختلف وجود دارند (مانند `node-exporter` برای متریک‌های سیستم، `kube-state-metrics` برای متریک‌های Kubernetes API، و Exporterهای خاص برای دیتابیس‌ها، وب سرورها و غیره).
- ‏**Instrumentation مستقیم:** برخی از کتابخانه‌ها و فریم‌ورک‌ها امکان Instrumentation مستقیم را فراهم می‌کنند، به این معنی که برنامه شما می‌تواند متریک‌ها را در قالب Prometheus در معرض قرار دهد بدون نیاز به یک Exporter جداگانه.
- ‏**cAdvisor:** Kubernetes به طور پیش‌فرض cAdvisor را روی هر Node اجرا می‌کند که متریک‌های مربوط به Containerها (CPU، حافظه، شبکه، دیسک) را در معرض قرار می‌دهد. Prometheus می‌تواند این متریک‌ها را نیز جمع‌آوری کند.

**2. استقرار Prometheus در Kubernetes:**

چندین راه برای استقرار Prometheus در Kubernetes وجود دارد:

- **فایل‌های YAML ساده:** برای استقرارهای کوچک و تست، می‌توانید از فایل‌های YAML برای تعریف Deployment، Service و سایر منابع Prometheus استفاده کنید.
- ‏**Helm:** Helm یک مدیر بسته برای Kubernetes است و استفاده از Chartهای Helm راهی استاندارد و آسان برای استقرار برنامه‌های پیچیده مانند Prometheus است. Chartهای محبوبی برای Prometheus وجود دارند (مانند `prometheus-community/kube-prometheus-stack`).
- ‏**Operator:** Prometheus Operator یک روش پیشرفته‌تر است که از Custom Resource Definitions (CRDs) برای مدیریت و پیکربندی استقرارهای Prometheus، Alertmanager و Grafana استفاده می‌کند. این روش امکان اتوماسیون و مدیریت آسان‌تر را فراهم می‌کند.

در این مثال، فرض می‌کنیم که از **Helm** با Chart `prometheus-community/kube-prometheus-stack` استفاده می‌کنیم که یک راه حل جامع برای نظارت بر Kubernetes است و شامل Prometheus، Alertmanager، Grafana و kube-state-metrics می‌شود.

**3. پیکربندی Prometheus برای کشف Podها:**

‏Prometheus برای جمع‌آوری متریک‌ها باید بداند که چگونه Podها و Exporterهای آن‌ها را پیدا کند. Kubernetes Service Discovery مکانیزم اصلی برای این کار است. شما باید Prometheus را پیکربندی کنید تا از طریق Kubernetes API Server، Podها و سرویس‌های مورد نظر را کشف کند.

‏Chart `kube-prometheus-stack` به طور پیش‌فرض تنظیمات مناسبی برای کشف سرویس‌ها و Podها ارائه می‌دهد. با این حال، ممکن است نیاز به پیکربندی اضافی داشته باشید. در تنظیمات Prometheus (`prometheus.yml` یا از طریق مقادیر Helm)، می‌توانید `scrape_configs` را تعریف کنید. یک مثال از یک `scrape_config` برای کشف Podهایی که دارای برچسب خاصی هستند و پورت مشخصی را برای متریک‌ها باز کرده‌اند:

YAML

```
scrape_configs:
  - job_name: 'my-app-metrics'
    kubernetes_sd_configs:
      - role: pod
    relabel_configs:
      - source_labels: [__meta_kubernetes_pod_label_app]
        target_label: app
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
        action: keep
        regex: true
      - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
        action: replace
        regex: ([^:]+)(?::\d+)?(,?)(\d+)
        replacement: $$1:$$4$$3
        target_label: __address__
      - source_labels: [__meta_kubernetes_pod_name]
        target_label: pod
```

توضیح تنظیمات بالا:

-‏ `job_name`: نام این پیکربندی جمع‌آوری.
- ‏`kubernetes_sd_configs`: پیکربندی برای کشف سرویس‌ها یا Podها از طریق Kubernetes API. `role: pod` به Prometheus می‌گوید که Podها را کشف کند.
- ‏`relabel_configs`: مجموعه‌ای از قوانین برای تغییر برچسب‌های کشف شده قبل از ذخیره شدن متریک‌ها.
    - برچسب `app` را از برچسب `__meta_kubernetes_pod_label_app` کپی می‌کند.
    - فقط Podهایی را نگه می‌دارد که دارای Annotation `prometheus.io/scrape: "true"` هستند.
    - پورت متریک را از Annotation `prometheus.io/port` استخراج کرده و آدرس جمع‌آوری را تنظیم می‌کند.
    - نام Pod را به عنوان برچسب `pod` اضافه می‌کند.

‏**4. Annotationها در Podها (روش رایج):**

یک روش رایج برای پیکربندی نحوه جمع‌آوری متریک از Podها، استفاده از Annotationها است. در Deployment یا Pod definition خود، می‌توانید Annotationهای زیر را اضافه کنید:

YAML

```
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-app
spec:
  template:
    metadata:
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "8080" # پورتی که Exporter متریک‌ها را ارائه می‌دهد
      labels:
        app: my-app
    spec:
      containers:
        - name: my-app-container
          image: my-app-image
          ports:
            - containerPort: 8080
```

با این Annotationها، Prometheus (اگر با `kubernetes_sd_configs` و `relabel_configs` مناسب پیکربندی شده باشد) به طور خودکار این Podها را کشف کرده و متریک‌های آن‌ها را از پورت 8080 جمع‌آوری می‌کند.

**5. استقرار Exporterها:**

مطمئن شوید که Exporterهای مورد نیاز در Podهای شما در حال اجرا هستند. برای مثال:

- برای جمع‌آوری متریک‌های سیستم (CPU، حافظه، دیسک) از هر Node، معمولاً از `node-exporter` به صورت DaemonSet استفاده می‌شود. Chart `kube-prometheus-stack` این را به طور پیش‌فرض مستقر می‌کند.
- برای جمع‌آوری متریک‌های مربوط به وضعیت اشیاء Kubernetes (مانند Deploymentها، StatefulSetها، Podها)، از `kube-state-metrics` استفاده می‌شود. این نیز معمولاً توسط `kube-prometheus-stack` مستقر می‌شود.
- برای برنامه‌های کاربردی خاص خود، ممکن است نیاز به استقرار Exporterهای جداگانه در کنار آن‌ها داشته باشید (به عنوان مثال، یک Container جداگانه در همان Pod).

**6. مشاهده متریک‌ها در Grafana:**

‏Chart `kube-prometheus-stack` معمولاً Grafana را نیز مستقر می‌کند و داشبوردهای پیش‌فرضی برای نظارت بر Kubernetes و برنامه‌های کاربردی رایج ارائه می‌دهد. شما می‌توانید از Grafana برای جستجو، تجسم و ایجاد نمودار از متریک‌های جمع‌آوری شده از Podهای خود استفاده کنید.

**7. نکات مهم:**

- **امنیت:** دسترسی به Prometheus و Grafana را محدود کنید. از مکانیزم‌های امنیتی Kubernetes مانند RBAC و Network Policy استفاده کنید.
- **منابع:** مطمئن شوید که منابع کافی (CPU، حافظه) برای Prometheus و Exporterهای خود اختصاص داده‌اید.
- **پایداری:** برای استقرارهای Production، از Persistent Volume برای ذخیره‌سازی داده‌های Prometheus استفاده کنید تا در صورت خرابی Pod، داده‌ها از بین نروند.
- **مقیاس‌پذیری:** برای کلاسترهای بزرگ، ممکن است نیاز به تنظیمات مقیاس‌پذیری برای Prometheus داشته باشید (مانند استفاده از Thanos برای تجمیع و آرشیو داده‌ها).
- **مانیتورینگ خود Prometheus:** حتماً متریک‌های مربوط به خود Prometheus را نیز نظارت کنید تا از سلامت و عملکرد آن اطمینان حاصل کنید.

با دنبال کردن این مراحل و پیکربندی مناسب، می‌توانید Prometheus را در Kubernetes مستقر کرده و به طور موثر متریک‌های مربوط به Podهای خود را جمع‌آوری و نظارت کنید. استفاده از Helm Chart `kube-prometheus-stack` یک راه شروع عالی است زیرا بسیاری از اجزای مورد نیاز را به صورت یکپارچه فراهم می‌کند.

![image](src/loki-architect.png)


![image](src/loki_detail.png)

Loki Stack یک سیستم تجمیع لاگ است که از سه جزء اصلی تشکیل شده است:

- ‏**Loki:** هسته اصلی سیستم است که مسئول ذخیره سازی و پرس و جوی لاگ ها می باشد. بر خلاف سایر سیستم های تجمیع لاگ، Loki محتوای لاگ ها را ایندکس نمی کند، بلکه فقط برچسب های (labels) مرتبط با هر جریان لاگ را ایندکس می کند. این امر باعث می شود Loki کارآمدتر و ارزان تر برای اجرا باشد. Loki از یک زبان پرس و جو قدرتمند به نام LogQL برای جستجو و فیلتر کردن لاگ ها استفاده می کند.
    
- ‏**Promtail:** یک عامل سبک وزن است که روی هر دستگاه یا کانتینر اجرا می شود و مسئول جمع آوری لاگ ها از منابع مختلف (مانند فایل ها، سیستم عامل، یا برنامه های کاربردی) و ارسال آنها به Loki است. Promtail لاگ ها را بر اساس برچسب هایی که شما تعریف می کنید، برچسب گذاری می کند.
    
- ‏**Grafana:** یک پلتفرم تجسم داده محبوب است که به شما امکان می دهد داشبوردهای قابل تنظیم برای نمایش لاگ ها و ایجاد نمودارها و هشدارهای مبتنی بر لاگ ایجاد کنید. Grafana به طور یکپارچه با Loki کار می کند و به شما امکان می دهد به راحتی لاگ های خود را جستجو، فیلتر و تجزیه و تحلیل کنید.
    

به طور خلاصه، Loki Stack یک راه حل قدرتمند و مقیاس پذیر برای مدیریت و تجزیه و تحلیل لاگ ها است. Promtail لاگ ها را جمع آوری و به Loki ارسال می کند، Loki آنها را ذخیره و ایندکس می کند، و Grafana یک رابط کاربری برای تجسم و پرس و جو از این لاگ ها فراهم می کند. این سه جزء با هم کار می کنند تا یک سیستم جامع برای مشاهده و درک رویدادهای سیستم شما ارائه دهند.

متوجه شدم، می‌خواهید در مورد اجزای داخلی Loki بیشتر بدانید. Loki به عنوان یک سیستم تجمیع لاگ، دارای اجزای داخلی متعددی است که با یکدیگر تعامل دارند تا عملکرد کلی آن را تضمین کنند. در اینجا به برخی از مهم‌ترین این اجزا اشاره می‌کنم:

**مسیر نوشتن (Write Path):**

-‏ **Distributor (توزیع کننده):** وظیفه اصلی این جزء، دریافت لاگ‌ها از Promtail یا سایر کلاینت‌ها است. Distributor تعیین می‌کند که کدام Ingester مسئول نوشتن هر جریان لاگ خواهد بود. این تصمیم‌گیری بر اساس یک هش ثابت از برچسب‌های جریان لاگ انجام می‌شود تا اطمینان حاصل شود که لاگ‌های با برچسب‌های یکسان همیشه به یک Ingester ارسال می‌شوند. Distributor همچنین لاگ‌ها را اعتبارسنجی کرده و آن‌ها را به صورت دسته‌ای برای Ingesterها ارسال می‌کند.
    
- ‏**Ingester (درون‌ریز):** این جزء مسئول نوشتن لاگ‌ها در حافظه (به صورت Chunk) و همچنین نوشتن آن‌ها در حافظه پایدار (Write-Ahead Log یا WAL) برای جلوگیری از از دست رفتن داده‌ها در صورت خرابی است. هر Ingester مسئول مجموعه‌ای از جریان‌های لاگ است. هنگامی که یک Chunk به اندازه کافی بزرگ شود یا مدت زمان مشخصی از ایجاد آن بگذرد، Ingester آن را فشرده کرده و به سیستم ذخیره‌سازی پشتیبان (مانند S3، GCS یا فایل سیستم محلی) منتقل می‌کند.
    
- ‏**Write-Ahead Log (WAL):** یک مکانیسم برای اطمینان از دوام داده‌ها است. قبل از اینکه لاگ‌ها در حافظه اصلی (Chunks) نوشته شوند، ابتدا در WAL ثبت می‌شوند. در صورت خرابی Ingester، می‌توان از WAL برای بازیابی لاگ‌هایی که هنوز به سیستم ذخیره‌سازی پشتیبان منتقل نشده‌اند، استفاده کرد.
    

**مسیر خواندن (Read Path):**

-‏ **Querier (پرسشگر):** این جزء مسئول دریافت پرس و جوها از Grafana یا کاربران است. Querier ابتدا از Index Gateway برای یافتن Chunkهای مرتبط با پرس و جو کمک می‌گیرد. سپس از Ingesterها داده‌های موجود در حافظه را درخواست می‌کند و Chunkهای ذخیره شده در سیستم ذخیره‌سازی پشتیبان را نیز بازیابی و پردازش می‌کند تا نتایج پرس و جو را برگرداند.
    
- ‏**Index Gateway (درگاه فهرست):** این جزء مسئول مدیریت و نگهداری فهرست (Index) از برچسب‌ها و ارتباط آن‌ها با Chunkهای ذخیره شده است. Index Gateway به Querier کمک می‌کند تا به سرعت Chunkهای مرتبط با یک پرس و جو را پیدا کند.
    
- ‏**Query Frontend (پیشخوان پرسش):** این جزء اختیاری است اما در استقرارهای بزرگ و با بار کاری زیاد توصیه می‌شود. Query Frontend درخواست‌های پرس و جو را دریافت کرده، آن‌ها را در یک صف قرار می‌دهد و سپس آن‌ها را به Querierهای موجود ارسال می‌کند. همچنین می‌تواند پرس و جوهای بزرگ را به چندین پرس و جوی کوچکتر تقسیم کرده و نتایج را ادغام کند. این کار به بهبود عملکرد و پایداری سیستم در هنگام پرس و جوهای سنگین کمک می‌کند.
    

**اجزای پس‌زمینه (Background Components):**

- ‏**Compactor (فشرده‌ساز):** این جزء مسئول فشرده‌سازی و سازماندهی Chunkها در سیستم ذخیره‌سازی پشتیبان است. Compactor Chunkهای کوچکتر را با هم ادغام کرده و آن‌ها را فشرده می‌کند تا کارایی ذخیره‌سازی و پرس و جو را بهبود بخشد. همچنین مسئول اعمال سیاست‌های نگهداری لاگ (Retention) می‌باشد.
    
-‏ **Ruler (قانون‌گذار):** این جزء مسئول ارزیابی قوانین هشدار (Alerting Rules) بر اساس داده‌های لاگ است. Ruler به طور دوره‌ای پرس و جوها را اجرا می‌کند و در صورت مطابقت با شرایط تعریف شده در قوانین، هشدارها را فعال می‌کند.
    

**مفاهیم کلیدی مرتبط:**

- ‏**Tenant (مستاجر):** Loki از چند مستاجری (Multi-tenancy) پشتیبانی می‌کند، به این معنی که چندین سازمان یا تیم می‌توانند از یک استقرار Loki به طور جداگانه استفاده کنند. هر جریان لاگ و داده‌های مرتبط با آن با یک Tenant ID مشخص می‌شود.
    
- ‏**Stream (جریان):** یک دنباله از لاگ‌ها که دارای مجموعه یکسانی از برچسب‌ها هستند. Loki بر اساس برچسب‌ها، جریان‌های لاگ را شناسایی و دسته‌بندی می‌کند.
    
- ‏**Chunk (تکه):** یک بلوک از لاگ‌های فشرده شده که برای یک جریان لاگ خاص در یک بازه زمانی مشخص ذخیره می‌شود.
    

درک این اجزای داخلی به شما کمک می‌کند تا معماری Loki را بهتر درک کرده و بتوانید آن را به طور موثرتر پیکربندی، مدیریت و عیب‌یابی کنید. بسته به مقیاس و نیازهای استقرار شما، می‌توانید Loki را در حالت‌های مختلفی (مانند Monolithic، Simple Scalable و Microservices) مستقر کنید که در آن‌ها برخی از این اجزا ممکن است در یک فرآیند واحد یا به صورت فرآیندهای جداگانه اجرا شوند.

